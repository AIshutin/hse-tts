defaults:
  - default
  - override data: onebatch_data

name: fastspeech2-v3-test
n_gpu: 1
preprocessing:
  sr: 22050
arch:
  _target_: tts.model.FastSpeech2Model
  vocab_size: 300
  max_seq_len: 3000
  encoder_dim: 256
  encoder_n_layer: 4
  encoder_head: 2
  encoder_conv1d_filter_size: 1024
  decoder_dim: 256
  decoder_n_layer: 4
  decoder_head: 2
  decoder_conv1d_filter_size: 1024
  fft_conv1d_kernel:
  - 9
  - 1
  fft_conv1d_padding:
  - 4
  - 0
  x_predictor_filter_size: 256
  x_predictor_kernel_size: 3
  x_predictor_dropout: 0.5
  energy_emb_dim: 256
  min_energy: 0.09309670329093933
  max_energy: 1.549446702003479
  n_quant_energy: 256
  pitch_emb_dim: 256
  min_pitch: 0.6945844909375258
  max_pitch: 7.6025340908123455
  n_quant_pitch: 256
  pitch_cwt_step: 0.02166
  pitch_spec_width: 124
  pitch_first_scale: 0.7879
  dropout: 0.1
  PAD: 0
  num_mels: 80
lr_scheduler:
  _target_: tts.scheduler.getTransformerScheduler
  warmup_steps: 1000
  d_model: 256
trainer:
  epochs: 40
  save_period: 1000
  verbosity: 2
  monitor: min val_loss
  save_dir: saved/${name}/
  early_stop: 100
  visualize: wandb
  wandb_project: tts_project
  len_epoch: 200
  grad_norm_clip: 1
